<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Parametric (neural network) Embedding &mdash; umap 0.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=1c40f30e"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="UMAP on sparse data" href="sparse.html" />
    <link rel="prev" title="Inverse transforms" href="inverse_transform.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html">
            
              <img src="_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.5
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide / Tutorial:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="basic_usage.html">How to Use UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameters.html">Basic UMAP Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">Plotting UMAP results</a></li>
<li class="toctree-l1"><a class="reference internal" href="reproducibility.html">UMAP Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="transform.html">Transforming New Data with UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="inverse_transform.html">Inverse transforms</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parametric (neural network) Embedding</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#defining-your-own-network">Defining your own network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#saving-and-loading-your-model">Saving and loading your model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plotting-loss">Plotting loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parametric-inverse-transform-reconstruction">Parametric inverse_transform (reconstruction)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#autoencoding-umap">Autoencoding UMAP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#early-stopping-and-keras-callbacks">Early stopping and Keras callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#additional-important-parameters">Additional important parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extending-the-model">Extending the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#citing-our-work">Citing our work</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">UMAP on sparse data</a></li>
<li class="toctree-l1"><a class="reference internal" href="supervised.html">UMAP for Supervised Dimension Reduction and Metric Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Using UMAP for Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="outliers.html">Outlier detection using UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="composing_models.html">Combining multiple UMAP models</a></li>
<li class="toctree-l1"><a class="reference internal" href="densmap_demo.html">Better Preserving Local Density with DensMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="mutual_nn_umap.html">Improving the Separation Between Similar Classes Using a Mutual k-NN Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="document_embedding.html">Document embedding using UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="embedding_space.html">Embedding to non-Euclidean spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="aligned_umap_basic_usage.html">How to use AlignedUMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="aligned_umap_politics_demo.html">AlignedUMAP for Time Varying Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="precomputed_k-nn.html">Precomputed k-nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Performance Comparison of Dimension Reduction Implementations</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background on UMAP:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="how_umap_works.html">How UMAP Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Performance Comparison of Dimension Reduction Implementations</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples of UMAP usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="interactive_viz.html">Interactive Visualizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="exploratory_analysis.html">Exploratory Analysis of Interesting Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="scientific_papers.html">Scientific Papers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">UMAP API Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">umap</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Parametric (neural network) Embedding</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/parametric_umap.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="parametric-neural-network-embedding">
<h1>Parametric (neural network) Embedding<a class="headerlink" href="#parametric-neural-network-embedding" title="Permalink to this heading"></a></h1>
<p>UMAP is comprised of two steps: First, compute a graph representing your data, second, learn an embedding for that graph:</p>
<img alt="_images/umap-only.png" src="_images/umap-only.png" />
<p>Parametric UMAP replaces the second step, minimizing the same objective function as UMAP (we’ll call it non-parametric UMAP here), but learning the relationship between the data and embedding using a neural network, rather than learning the embeddings directly:</p>
<img alt="_images/pumap-only.png" src="_images/pumap-only.png" />
<p>Parametric UMAP is simply a subclass of UMAP, so it can be used just like nonparametric UMAP, replacing <code class="code highlight python docutils literal highlight-python"><span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span></code> with <code class="code highlight python docutils literal highlight-python"><span class="n">parametric_umap</span><span class="o">.</span><span class="n">ParametricUMAP</span></code>. The most basic usage of parametric UMAP would be to simply replace UMAP with ParametricUMAP in your code:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">umap.parametric_umap</span> <span class="kn">import</span> <span class="n">ParametricUMAP</span>
<span class="n">embedder</span> <span class="o">=</span> <span class="n">ParametricUMAP</span><span class="p">()</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">my_data</span><span class="p">)</span>
</pre></div>
</div>
<p>In this implementation, we use Keras and Tensorflow as a backend to train that neural network. The added complexity of a learned embedding presents a number of configurable settings available in addition to those in non-parametric UMAP. A set of Jupyter notebooks walking you through these parameters are available on the  <a class="reference external" href="https://github.com/lmcinnes/umap/tree/master/notebooks/Parametric_UMAP">GitHub repository</a></p>
<section id="defining-your-own-network">
<h2>Defining your own network<a class="headerlink" href="#defining-your-own-network" title="Permalink to this heading"></a></h2>
<p>By default, Parametric UMAP uses 3-layer 100-neuron fully-connected neural network. To extend Parametric UMAP to use a more complex architecture, like a convolutional neural network, we simply need to define the network and pass it in as an argument to ParametricUMAP. This can be done easliy, using tf.keras.Sequential. Here’s an example for MNIST:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the network</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">dims</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">dims</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
        <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span>
    <span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
        <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span>
    <span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">n_components</span><span class="p">),</span>
<span class="p">])</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p>To load pass the data into ParametricUMAP, we first need to flatten it from 28x28x1 images to a 784-dimensional vector.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="mf">255.</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="mf">255.</span>
</pre></div>
</div>
<p>We can then pass the network into ParametricUMAP and train:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pass encoder network to ParametricUMAP</span>
<span class="n">embedder</span> <span class="o">=</span> <span class="n">ParametricUMAP</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">)</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>
</pre></div>
</div>
<p>If you are unfamilar with Tensorflow/Keras and want to train your own model, we reccomend that you take a look at the <a class="reference external" href="https://www.tensorflow.org/">Tensorflow documentation</a>.</p>
</section>
<section id="saving-and-loading-your-model">
<h2>Saving and loading your model<a class="headerlink" href="#saving-and-loading-your-model" title="Permalink to this heading"></a></h2>
<p>Unlike non-parametric UMAP Parametric UMAP cannot be saved simply by pickling the UMAP object because of the Keras networks it contains. To save Parametric UMAP, there is a built in function:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedder</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/your/path/here&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can then load parametric UMAP elsewhere:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">umap.parametric_umap</span> <span class="kn">import</span> <span class="n">load_ParametricUMAP</span>
<span class="n">embedder</span> <span class="o">=</span> <span class="n">load_ParametricUMAP</span><span class="p">(</span><span class="s1">&#39;/your/path/here&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This loads both the UMAP object and the parametric networks it contains.</p>
</section>
<section id="plotting-loss">
<h2>Plotting loss<a class="headerlink" href="#plotting-loss" title="Permalink to this heading"></a></h2>
<p>Parametric UMAP monitors loss during training using Keras. That loss will be printed after each epoch during training. This loss is saved in <code class="code highlight python docutils literal highlight-python"><span class="n">embedder</span><span class="o">.</span><span class="n">history</span></code>, and can be plotted:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">embedder</span><span class="o">.</span><span class="n">_history</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">embedder</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cross Entropy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/umap-loss.png" src="_images/umap-loss.png" />
</section>
<section id="parametric-inverse-transform-reconstruction">
<h2>Parametric inverse_transform (reconstruction)<a class="headerlink" href="#parametric-inverse-transform-reconstruction" title="Permalink to this heading"></a></h2>
<p>To use a second neural network to learn an inverse mapping between data and embeddings, we simply need to pass <cite>parametric_reconstruction= True</cite> to the ParametricUMAP.</p>
<p>Like the encoder, a custom decoder can also be passed to ParametricUMAP, e.g.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_components</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
        <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span>
    <span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
        <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span>
    <span class="p">),</span>

<span class="p">])</span>
</pre></div>
</div>
<p>In addition, validation data can be used to test reconstruction loss on out-of-dataset samples:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">validation_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="mf">255.</span>
</pre></div>
</div>
<p>Finally, we can pass the validation data and the networks to ParametricUMAP and train:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedder</span> <span class="o">=</span> <span class="n">ParametricUMAP</span><span class="p">(</span>
    <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
    <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
    <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span>
    <span class="n">parametric_reconstruction</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">reconstruction_validation</span><span class="o">=</span><span class="n">validation_images</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="autoencoding-umap">
<h2>Autoencoding UMAP<a class="headerlink" href="#autoencoding-umap" title="Permalink to this heading"></a></h2>
<p>In the example above, the encoder is trained to minimize UMAP loss, and the decoder is trained to minimize reconstruction loss. To train the encoder jointly on both UMAP loss and reconstruction loss, pass <code class="code highlight python docutils literal highlight-python"><span class="n">autoencoder_loss</span> <span class="o">=</span> <span class="kc">True</span></code> into the ParametricUMAP.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedder</span> <span class="o">=</span> <span class="n">ParametricUMAP</span><span class="p">(</span>
    <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
    <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
    <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span>
    <span class="n">parametric_reconstruction</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">reconstruction_validation</span><span class="o">=</span><span class="n">validation_images</span><span class="p">,</span>
    <span class="n">autoencoder_loss</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="early-stopping-and-keras-callbacks">
<h2>Early stopping and Keras callbacks<a class="headerlink" href="#early-stopping-and-keras-callbacks" title="Permalink to this heading"></a></h2>
<p>It can sometimes be useful to train the embedder until some plateau in training loss is met. In deep learning, early stopping is one way to do this. Keras provides custom <a class="reference external" href="https://keras.io/api/callbacks/">callbacks</a> that allow you to implement checks during training, such as early stopping. We can use callbacks, such as early stopping, with ParametricUMAP to stop training early based on a predefined training threshold, using the <code class="code highlight python docutils literal highlight-python"><span class="n">keras_fit_kwargs</span></code> argument:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">keras_fit_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;callbacks&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
        <span class="n">min_delta</span><span class="o">=</span><span class="mi">10</span><span class="o">**-</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">]}</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">ParametricUMAP</span><span class="p">(</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">keras_fit_kwargs</span> <span class="o">=</span> <span class="n">keras_fit_kwargs</span><span class="p">,</span>
    <span class="n">n_training_epochs</span><span class="o">=</span><span class="mi">20</span>
<span class="p">)</span>
</pre></div>
</div>
<p>We also passed in <code class="code highlight python docutils literal highlight-python"><span class="n">n_training_epochs</span> <span class="o">=</span> <span class="mi">20</span></code>, allowing early stopping to end training before 20 epochs are reached.</p>
</section>
<section id="additional-important-parameters">
<h2>Additional important parameters<a class="headerlink" href="#additional-important-parameters" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p><strong>batch_size:</strong> ParametricUMAP in trained over batches of edges randomly sampled from the UMAP graph, and then trained via gradient descent.  ParametricUMAP defaults to a batch size of 1000 edges, but can be adjusted to a value that fits better on your GPU or CPU.</p></li>
<li><p><strong>loss_report_frequency:</strong> If set to 1, an epoch in in the Keras embedding refers to a single iteration over the graph computed in UMAP. Setting <code class="code highlight python docutils literal highlight-python"><span class="n">loss_report_frequency</span></code> to 10, would split up that epoch into 10 seperate epochs, for more frequent reporting.</p></li>
<li><p><strong>n_training_epochs:</strong> The number of epochs over the UMAP graph to train for (irrespective of <code class="code highlight python docutils literal highlight-python"><span class="n">loss_report_frequency</span></code>). Training the network for multiple epochs will result in better embeddings, but take longer. This parameter is different than <code class="code highlight python docutils literal highlight-python"><span class="n">n_epochs</span></code> in the base UMAP class, which corresponds to the maximum number of times an edge is trained in a single ParametricUMAP epoch.</p></li>
<li><p><strong>optimizer:</strong> The optimizer used to train the neural network. by default Adam (<code class="code highlight python docutils literal highlight-python"><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span></code>) is used. You might be able to speed up or improve training by using a different optimizer.</p></li>
<li><p><strong>parametric_embedding:</strong> If set to false, a non-parametric embedding is learned, using the same code as the parametric embedding, which can serve as a direct comparison between parametric and non-parametric embedding using the same optimizer. The parametric embeddings are performed over the entire dataset simultaneously.</p></li>
<li><p><strong>global_correlation_loss_weight:</strong> Whether to additionally train on correlation of global pairwise relationships (multidimensional scaling)</p></li>
</ul>
</section>
<section id="extending-the-model">
<h2>Extending the model<a class="headerlink" href="#extending-the-model" title="Permalink to this heading"></a></h2>
<p>You may want to customize parametric UMAP beyond what we have implemented in this package. To make it as easy as possible to tinker around with Parametric UMAP, we made a few Jupyter notebooks that show you how to extend Parametric UMAP to your own use-cases.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://colab.research.google.com/drive/1WkXVZ5pnMrm17m0YgmtoNjM_XHdnE5Vp?usp=sharing">https://colab.research.google.com/drive/1WkXVZ5pnMrm17m0YgmtoNjM_XHdnE5Vp?usp=sharing</a></p></li>
</ul>
</section>
<section id="citing-our-work">
<h2>Citing our work<a class="headerlink" href="#citing-our-work" title="Permalink to this heading"></a></h2>
<p>If you use Parametric UMAP in your work, please cite our paper:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="w"> </span><span class="nc">@article</span><span class="p">{</span><span class="nl">sainburg2021parametric</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Parametric UMAP Embeddings for Representation and Semisupervised Learning}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Sainburg, Tim and McInnes, Leland and Gentner, Timothy Q}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{Neural Computation}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="p">=</span><span class="s">{33}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="p">=</span><span class="s">{11}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{2881--2907}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
<span class="w">  </span><span class="na">publisher</span><span class="p">=</span><span class="s">{MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="inverse_transform.html" class="btn btn-neutral float-left" title="Inverse transforms" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="sparse.html" class="btn btn-neutral float-right" title="UMAP on sparse data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, Leland McInnes.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>