<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Outlier detection using UMAP &mdash; umap 0.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=1c40f30e"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Combining multiple UMAP models" href="composing_models.html" />
    <link rel="prev" title="Using UMAP for Clustering" href="clustering.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html">
            
              <img src="_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.5
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide / Tutorial:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="basic_usage.html">How to Use UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameters.html">Basic UMAP Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">Plotting UMAP results</a></li>
<li class="toctree-l1"><a class="reference internal" href="reproducibility.html">UMAP Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="transform.html">Transforming New Data with UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="inverse_transform.html">Inverse transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="parametric_umap.html">Parametric (neural network) Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">UMAP on sparse data</a></li>
<li class="toctree-l1"><a class="reference internal" href="supervised.html">UMAP for Supervised Dimension Reduction and Metric Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Using UMAP for Clustering</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Outlier detection using UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="composing_models.html">Combining multiple UMAP models</a></li>
<li class="toctree-l1"><a class="reference internal" href="densmap_demo.html">Better Preserving Local Density with DensMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="mutual_nn_umap.html">Improving the Separation Between Similar Classes Using a Mutual k-NN Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="document_embedding.html">Document embedding using UMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="embedding_space.html">Embedding to non-Euclidean spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="aligned_umap_basic_usage.html">How to use AlignedUMAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="aligned_umap_politics_demo.html">AlignedUMAP for Time Varying Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="precomputed_k-nn.html">Precomputed k-nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Performance Comparison of Dimension Reduction Implementations</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background on UMAP:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="how_umap_works.html">How UMAP Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Performance Comparison of Dimension Reduction Implementations</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples of UMAP usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="interactive_viz.html">Interactive Visualizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="exploratory_analysis.html">Exploratory Analysis of Interesting Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="scientific_papers.html">Scientific Papers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">UMAP API Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">umap</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Outlier detection using UMAP</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/outliers.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="outlier-detection-using-umap">
<h1>Outlier detection using UMAP<a class="headerlink" href="#outlier-detection-using-umap" title="Permalink to this heading"></a></h1>
<p>While an earlier tutorial looked at using <a class="reference external" href="https://umap-learn.readthedocs.io/en/latest/clustering.html">UMAP for
clustering</a>,
it can also be used for outlier detection, providing that some care is
taken. This tutorial will look at how to use UMAP in this manner, and
what to look out for, by finding anomalous digits in the MNIST
handwritten digits dataset. To start with let’s load the relevant
libraries:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn.datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.neighbors</span>
<span class="kn">import</span> <span class="nn">umap</span>
<span class="kn">import</span> <span class="nn">umap.plot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>
</div>
<p>With this in hand, let’s grab the MNIST digits dataset from the
internet, using the new <code class="docutils literal notranslate"><span class="pre">fetch_ml</span></code> loader in sklearn.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Before we get started we should try looking for outliers in terms of the
native 784 dimensional space that MNIST digits live in. To do this we
will make use of the <a class="reference external" href="https://en.wikipedia.org/wiki/Local_outlier_factor">Local Outlier Factor
(LOF)</a> method for
determining outliers since sklearn has an easy to use implementation.
The essential intuition of LOF is to look for points that have a
(locally approximated) density that differs significantly from the
average density of their neighbors. In our case the actual details are
not so important – it is enough to know that the algorithm is
reasonably robust and effective on vector space data. We can apply it
using the <code class="docutils literal notranslate"><span class="pre">fit_predict</span></code> method of the sklearn class. The LOF class
take a parameter <code class="docutils literal notranslate"><span class="pre">contamination</span></code> which specifies the percentage of
data that the user expects to be noise. For this use case we will set it
to 0.001428 since, given the 70,000 samples in MNIST, this will result
in 100 outliers, which we can then look at in more detail.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">outlier_scores</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">neighbors</span><span class="o">.</span><span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">contamination</span><span class="o">=</span><span class="mf">0.001428</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mi">1</span><span class="n">h</span> <span class="mi">29</span><span class="nb">min</span> <span class="mi">10</span><span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mf">12.4</span> <span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mi">1</span><span class="n">h</span> <span class="mi">29</span><span class="nb">min</span> <span class="mi">22</span><span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">1</span><span class="n">h</span> <span class="mi">29</span><span class="nb">min</span> <span class="mi">53</span><span class="n">s</span>
</pre></div>
</div>
<p>It is worth noting how long that took. Over an hour and a half! Why did
it take so long? Because LOF requires a notion of density, which in turn
relies on a nearest neighbor type computation – which is expensive in
sklearn for high dimensional data. This alone is potentially a reason to
look at reducing the dimension of the data – it makes it more amenable
to existing techniques like LOF.</p>
<p>Now that we have a set of outlier scores we can find the actual outlying
digit images – these are the ones with scores equal to -1. Let’s
extract that data, and check that we got 100 different digit images.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">outlying_digits</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">outlier_scores</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">outlying_digits</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
</pre></div>
</div>
<p>Now that we have the outlying digit images the first question we should
be asking is “what do they look like?”. Fortunately for us we can
convert the 784 dimensional vectors back into image and plot them,
making it easier to look at. Since we extracted the 100 most outlying
digit images we can just display a 10x10 grid of them.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">outlying_digits</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="_images/outliers_9_0.png" src="_images/outliers_9_0.png" />
<p>These do certainly look like somewhat strange looking handwritten
digits, so our outlier detection seems to be working to some extent.</p>
<p>Now let’s try a naive approach using UMAP and see how far that gets us.
First let’s just apply UMAP directly with default parameters to the
MNIST data.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">mapper</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we can see what we got using the new plotting tools in umap.plot.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">umap</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">points</span><span class="p">(</span><span class="n">mapper</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">_subplots</span><span class="o">.</span><span class="n">AxesSubplot</span> <span class="n">at</span> <span class="mh">0x1c3db71358</span><span class="o">&gt;</span>
</pre></div>
</div>
<img alt="_images/outliers_13_2.png" src="_images/outliers_13_2.png" />
<p>That looks like what we have come to expect from a UMAP embedding of
MNIST. The question is have we managed to preserve outliers well enough
that LOF can still find the bizarre digit images, or has the embedding
lost that information and contracted the outliers into the individual
digit clusters? We can simply apply LOF to the embedding and see what
that returns.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">outlier_scores</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">neighbors</span><span class="o">.</span><span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">contamination</span><span class="o">=</span><span class="mf">0.001428</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mapper</span><span class="o">.</span><span class="n">embedding_</span><span class="p">)</span>
</pre></div>
</div>
<p>This was obviously much faster since we are operating in a much lower
dimensional space that is more amenable to the spatial indexing methods
that sklearn uses to find nearest neighbors. As before we extract the
outlying digit images, and verify that we got 100 of them,</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">outlying_digits</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">outlier_scores</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">outlying_digits</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we need to plot the outlying digit images to see what kinds of digit
images this approach found to be particularly strange.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">outlying_digits</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="_images/outliers_19_0.png" src="_images/outliers_19_0.png" />
<p>In many ways this looks to be a <em>better</em> result than the original LOF in
the high dimensional space. While the digit images that the high
dimensional LOF found to be strange were indeed somewhat odd looking,
many of these digit images are considerably stranger – significantly
odd line thickness, warped shapes, and images that are hard to even
recognise as digits. This helps to demonstrate a certain amount of
confirmation bias when examining outliers: since we expect things tagged
as outliers to be strange we tend to find aspects of them that justify
that classification, potentially unaware of how much stranger some of
the data may in fact be. This should make us wary of even this outlier
set: what else might lurk in the dataset?</p>
<p>We can, in fact, potentially improve on this result by tuning the UMAP
embedding a little for the task of finding outliers. When UMAP combines
together the different local simplicial sets (see <a class="reference internal" href="how_umap_works.html"><span class="doc">How UMAP Works</span></a>
for more details) the standard approach uses a union, but we could
instead take an intersection. An intersection ensures that outliers
remain disconnected, which is certainly beneficial when seeking to find
outliers. A downside of the intersection is that it tends to break up
the resulting simplicial set into many disconnected components and a lot
of the more non-local and global structure is lost, resulting in a lot
lower quality of the resulting embedding. We can, however, interpolate
between the union and intersection. In UMAP this is given by the
<code class="docutils literal notranslate"><span class="pre">set_op_mix_ratio</span></code>, where a value of 0.0 represents an intersection,
and a value of 1.0 represents a union (the default value is 1.0). By
setting this to a lower value, say 0.25, we can encourage the embedding
to do a better job of preserving outliers as outlying, while still
retaining the benefits of a union operation.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">mapper</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span><span class="n">set_op_mix_ratio</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">umap</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">points</span><span class="p">(</span><span class="n">mapper</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">_subplots</span><span class="o">.</span><span class="n">AxesSubplot</span> <span class="n">at</span> <span class="mh">0x1c3f496908</span><span class="o">&gt;</span>
</pre></div>
</div>
<img alt="_images/outliers_22_2.png" src="_images/outliers_22_2.png" />
<p>As you can see the embedding is not as well structured overall as when
we had a <code class="docutils literal notranslate"><span class="pre">set_op_mix_ratio</span></code> of 1.0, but we have potentially done a
better job of ensuring that outliers remain outlying. We can test that
hypothesis by running LOF on this embedding and looking at the resulting
digit images we get out. Ideally we should expect to find some
potentially even stranger results.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">outlier_scores</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">neighbors</span><span class="o">.</span><span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">contamination</span><span class="o">=</span><span class="mf">0.001428</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mapper</span><span class="o">.</span><span class="n">embedding_</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">outlying_digits</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">outlier_scores</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">outlying_digits</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
</pre></div>
</div>
<p>We have the expected 100 most outlying digit images, so let’s visualise
the results and see if they really are particularly strange.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">outlying_digits</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="_images/outliers_27_0.png" src="_images/outliers_27_0.png" />
<p>Here we see that the line thickness variation (particularly “fat”
digits, or particularly “fine” lines) that the original embedding helped
surface come through even more strongly here. We also see a number of
clearly corrupted images with extra lines, dots, or strange blurring
occurring.</p>
<p>So, in summary, using UMAP to reduce dimension prior to running
classical outlier detection methods such as LOF can improve both the
speed with which the algorithm runs, and the quality of results the
outlier detection can find. Furthermore we have introduced the
<code class="docutils literal notranslate"><span class="pre">set_op_mix_ratio</span></code> parameter, and explained how it can be used to
potentially improve the performance of outlier detection approaches
applied to UMAP embeddings.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="clustering.html" class="btn btn-neutral float-left" title="Using UMAP for Clustering" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="composing_models.html" class="btn btn-neutral float-right" title="Combining multiple UMAP models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, Leland McInnes.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>